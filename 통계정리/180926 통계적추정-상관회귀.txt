# 통계적 추정 - 상관, 회귀

# 상관분석?
- 변수 x, y가 있을 때 두 변수가 서로 어떠한 관계가 있는지 파악하는 것.
- 산점도를 바탕으로 어떠한 관계가 있는지 파악함.
- 한 쪽이 증가, 다른 변수도 증가 > 양의 상관관계
- 한 쪽은 증가, 다른 변수는 감소 > 음의 상관관계
※ 어떠한 관계가 있는지(음, 양)은 파악할 수 있지만 서로 인과관계를 파악할 수는 없다.

# 상관계수?
- 산점도를 기준으로 두 그래프가 모두 양의 상관관계일 수 있다.
- 두 그래프 모두 양의 상관관계이지만 점들간의 간격(밀도)은 다를 수 있다.
- 이 밀도를 숫자로 표현하는데 이를 상관계수라고한다.
- -1~ 1사이로 표현함. -1은 음의 상관관계, 1은 양의 상관관계.

# 상관계수 구하기
- 산점도에서 일정한 패턴에 점들이 분포한다는 것을 알 수 있음.
- 일정한 패턴이 있지만 각각 조금씩 떨어져 있음.
- 이 떨어져있는 치우침을 활용하면 상관계수를 구할 수 있다.
- 이를 계산할 때 통계에서는 분산을 활용한다.
- 공식 : 공분산 / √(x의분산*y의분산)

# 공분산이란?
- 상관분석은 기본적으로 변수가 두 개이기 때문에 치우침이 두 변수에 의해 발생함.
- 그러므로 각각의 분산 외에 추가로 두 변수의 공통된 치우침도 알아야 한다.
- 두 개의 확률변수의 분포가 결합된 결합확률분포의 분산, 방향성은 o, 결합정도는 x
- 공분산이 0보다 크면 두 변수는 같은 방향으로 움직이고 0보다 작으면 다른 방향으로 움직인다.
- 만약 공분산이 0이라면 두 변수간에는 아무 선형관계가 없고 두 변수는 독립적이다.(항상 그런것은 아니다. )
※ 두 변수가 독립적이라면 공분산이 0이지만, 공분산이 0이라고 항상 독립적인 것은 아니다.
※ 상관계수 추가 설명
- 두 확률변수 사이의 선형적 관계정도를 나타내는 척도
- 공분산을 각 변수의 표준편차로 모두 나누어 구할 수 있다. > -1과 1사이 값으로 나옴
- 공분산은 원래 단위의 곱이 되기 떄문에 경우에 따라 표준화할 필요가 있음.
- 표준화한 결과가 상관계수가 된다.


# 상관계수의 가설검정 개념
- 상관분석은 상관계수의 수치로 관계의 정도를 파악함.
- 기본 맥락은 다른 가설검정과 비슷함.


# 회귀분석?
- 상관분석과 연관이 있긴하다.
- 상관분석은 두 변수가 상관이 있는지 분석을 하는 것.
- 회귀 분석은? 산점도에서 일정한 패턴을 찾아내고 이를 활용해 무엇인가를 예측하는 분석.
- 정답은 아니고 예측값이다.

# 회귀식 구하기
- 함수식 구하는 것과 비슷함
- y= a+ bx로 일반적인 회귀식을 표현한다.
- y는 구하는 예측값을 뜻하고  a는 y절편을, 기울기를 나타내는 b를 뜻함.
- 기울기를 알아야 y절편을 구할 수 있으므로 보통 기울기를 먼저 구하고 이 때 최소제곱법을 사용한다.
- 기울기를 구했다면 y절편은 x에 0을 넣으면 되지만 회귀분석에서는 그렇게 못 구함.
- why? 표본을 데이터로 사용하기 때문에 x=0인 상황이 드물기 때문임.
- 회귀식에선 예측값에 변수 y의 평균을, x에 변수 x의 평균을 넣어서 y절편을 구한다.
- 구해진 회귀식을 바탕으로 예측 기법을 사용할 수 있음.

# 회귀분석 과정 요약
- 1. 그래프(산점도)를 통해 선형인지 비선형인지 확인함.
- 2. 회귀식, 모델링 진행
- 3. 결과 확인


# 단순 선형 회귀분석
- 하나의 종속변수에 하나의 독립변수가 미치는 영향을 관찰
- 회귀식, fitted value, 잔차, 전체 결과 등 관찰 가능.

# 다중회귀분석
- 하나의 종속변수에 여러 독립변수가 미치는 영향을 살피는 회귀분석.
- 다중회귀분석 결과에는 Multiple R-squared(결정계수)와 Adjusted R-squred(수정된 결정계수)가 있다.
- 결정 계수 : 독립변수가 종속변수를 얼마나 잘 설명하고 있는가를 나타내는 계수 (상관계수의 제곱)

- 다중회귀분석의 독립 변수가 늘어날수록 결정계수는 높아진다.
- 그러므로 일반 결정계수가 아닌 수정된 결정계수을 사용해 설명력을 나타낸다.
- 수정된 결정계수는 항상 결정계수보다 낮게 나옴.
- 독립변수가 추가된다고 해서 항상 증가하지 않음
- 독립변수의 수가 적고 표본의 수가 클수록 결정계수의 값에 가까워진다.
- 표본에서 얻어진 결정계수의 값은 모집단에서 얻어진 결정계수 보다 약간 커진다.
- 이를 보완해주는 것이 수정된 결정게수이다.
- 변수의 수가 늘어난다면 수정된 결정게수로 적합도를 판단하는 것이 효율적이다.
- 모형의 적합도를 방해하는 요인이 늘어나게 되면 오히려 값이 줄어들 수 있다.

# 단계적 회귀분석
- 1. 후진제거법 : 독립변수를 모두 포함시킨 모형에서 분석을 시작
			   가장 영향력이 적은 변수부터 제거하여 더 이상 제거할 변수가 없을 때 모형을 최정적으로 선택하여
			   분석을 시작한다.
- 2. 전진 제거법 : 종속변수에서 가장 영향력을 주는 독립변수부터 ㅁ노형에 포함시키며 더 이상 추가될 독립변수가
				없을 때 변수의 선택을 중단하고 분석을 시작한다. (Null 모델부터 시작한다.)
				lwr : Null 모델, upper : 모든 변수 회귀 모델
- 3. 단계적 방법 : 여러개의 독립 변수 중 설명ㄹ력이 가장 높은 독립변수부터 차례 차례 삽입한 다음 의미 없는
				독립 변수를 제거하는 방식이다.
				upper : 모든 변수 회귀 모델
			   

			   
			   
# 로지스틱 회귀분석
- 이항 회귀 모형, 범주형 변수
- 일반화선형모형(Generalized Linear Model, GLM)의 이항분포를 따르는 모형의 일부로 해석하기도 한다.
- 새로운 설명변수(또는 예측변수)의 값이 주어질 때 반응변수에 속할 확률이 얼마인지를 추정
- 이항형인 데이터에 적용하였을 때 종속 변수 y의 결과가 이분적으로 제한(0,1)
- 종속 변수가 이진적이기 때문에 조건부 확률의 분포가 정규 분포 대신 이항 분포를 따른다.
- 로지스틱 회귀가 분류의 목적으로 사용될 경우에는 기준값보다 크면 1, 작으면 0인 집단과 같은 방식으로 분류
- ex) 어떤 고객이 탈퇴할지 안할지, 타이타닉에서 생존할지 사망할지 등











