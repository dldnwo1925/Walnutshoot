# 머신러닝

# 머신러닝이란?
- 데이터를 이용한 모델링 기법
- 데이터 -> 모델 (데이터 = 문자, 음성, 이미지 등 자료 / 모델 = 최종 결과물)
- 머신러닝 기법으로 모델을 찾아내는 과정이 마치 기게가 데이터를 학습해 모델을 찾아내는 것 > 기계 학습
- 모델링에 사용하는 데이터를 학습 데이터(training data)라고 함.
- 실제 데이터의 특성이 잘 반영되어 있으며 편향되어 있지 않은 학습 데이터를 확보하는 것이 굉장히 중요함.
- 학습 데이터와 입력 데이터가 달라도 성능 차이가 나지 않게 하는 것을 일반화 라고 함.
  머신러닝의 성패는 일반화가 잘 되었는지에 달려있음.

# 과적합
- 일반화의 성능을 떨어뜨리는 주범
※ 과적합이란 ?
- 학습 데이터를 모두 정답이라고 생각하고 모델을 너무 정확하게 설계하다 보면 일반화 성능이 떨어지는 현상.
- 과소적합, 적정적합, 과잉적합
- 과소적합 : 훈련 과정이 부족해 성능 자체가 떨어짐
- 적정적합 : 훈련 데이터를 통해 만든 모델의 성능이 약간 오류는 있지만 적절한 분류가 가능함.
		   실제 데이터를 통해서도 성능 차이가 별로 없음.
- 과잉적합 : 훈련 데이터를 통해 만든 모델의 성능이 100% 최고의 성능, 그러나 실제 데이터 셋에서 과잉적합 오류로
		   65%의 성능밖에 발휘를 못함. > 잘못된 설계

# 과적합을 방지하는 방법
- Validation Set > Cross-Validation

1. Training with all original data set - 문제 인식
- 가지고 있는 데이터 셋을 몽땅 학습 데이터로 훈련시키면 과소적합인지 적정, 과잉인지 판단하기 힘들다.
- 훈련을 시키면 시킬수록 에러확률은 줄어들기 때문에 결국은 과적합으로 귀결됨.
- 중간 적정적합구간에서 훈련을 중단시켜야하는 필요성. 
- 모든 데이터를 학습 데이터로 사용하면 훈련을 어디서 중단시켜야하는지 알 수 없다. 문제 발생과 인식단계.

2 Training Set vs. Validation Set
- 과적합을 탐지, 방지하기 위해 보유하고 있는 데이터셋을 학습 데이터(50~60%), 검증 데이터(20~25%),
  실제 데이터(20~25%) 3개의 set으로 나눈다.
- 학습 데이터를 통해 훈련시킨 후 검증 데이터를 통해 과적합, 과소적합에 빠져있지 않은지 검증을 하며
  적정적합 구간을 찾아 모델을 선택한다.
- 실제 데이터를 사용해 최종 모델에 대한 성적을 측정한다.

- 학습 데이터를 통해 만든 모델링을 통해 검증 데이터를 입력했을 때 에러율이 감소하다가 어느 순간 부터 증가하는
  지점이 있다.(보통 학습 데이터의 에러보다 검증 데이터의 에러가 조금씩 높음)
  이 변곡점이 과적합이 시작되는 지점으로 의심을 할 수 있음.
- 이 변곡점을 지나서 계속 훈련시키게 되면 일반화 과정이 아닌 학습 데이터 자체를 통째로 외우게 됨.
  > 처음 보는 데이터(검증 데이터)에 대해 자꾸 오답을 내게 되어 에러율이 올라가는 것.

3. k-fold Cross Validation
- 데이터 셋을 훈련/검증/실제 데이터로 나누었을 때 데이터 셋의 크기가 작을 경우 문제가 심각해질 수 있다.
- 데이터가 충분하지 못한 상태에서 3가지 데이터셋으로 나누었을 때 모델에 영향이 많이 갈 것이기 떄문이다.

- 이럴 경우 k-fold Cross Validation을 사용하면 좋다.
※ k-fold Cross Validation 이란?
- 학습 데이터를 k등분 후 k-1개의 fold는 학습 데이터로 사용하고 나머지 1개의 fold를 검증 데이터로 사용하며
  검증 데이터에 해당하는 fold를 round를 거듭하면서 바꿔주게 된다.
- 예를 들어 fold를 5개로 등분했다면 1개의 폴드마다 돌아가면서 검증 데이터 셋이 되는 것.
- 5round를 시행하여 분류 모형(classifier)을 선택하고 실제 데이터를 통해 최종모형을 평가하는 것을
- 극단적으로 시행할 경우 관측치 수 만큼 하는 경우도 있는데 이를 leave-one-out Cross-Validation(LOOCV)
  라고 한다. 보유하고 있는 데이터를 정부 활용하는 장점이 있지만 비용이 많이 들어 데이터 샘플이 작을 경우 유용함.
- 샘플 사이즈가 크다면 보통 10-fold Cross-Validation을 사용함.

4. 과적합 해결
- 과적합 문제에 대항하는 대표적 기법인 정직화(Regularization)와 검증(Validation)을 알아보자.
※ 정직화란?
- 모델의 형태를 최대한 간단하게 만들려느느 수치해석적인 기법. 복잡한 모델에서는 과적합이 일어나기 쉬움.
  학습 데이터의 대한 모델의 성능을 약간 희생하더라도 모델을 최대한 간단하게 만들어 과적합에 빠지지 않게 하자는 것이 바탕
- 단순한 모델이 몇몇 데이터를 제대로 분류하진 못했지만 전체적인 성능은 더 뛰어난 것이 정직화의 에이다.
- 실제 활용하는 데이터는 입력 데이터의 차원이 높기 때문에 그림으로 그려 과적합 여부를 직관적으로 알아내기는 불가능
- 과적합 여부를 판단할 수 있는 새로운 방법이 필요하다 > 검증의 필요성

※ 검증이란?
- 학습 데이터의 일부를 따로 뗴어 내 학습에는 사용하지 않고 모델의 성능 검증용으로 사용하는 기법.
- 즉 학습 데이터에 대한 모델의 오차로는 과적합 여부를 판단하기 불가능 해 일부 학습 데이터를 검증 데이터로 사용해
  과적합을 검증하겠다는 의도.
- 학습 데이터를 학습과 검증 데이터로 다시 나눔.
- 학습 데이터로 모델을 학습시킨 후 검증 데이터로 모델의 성능 평가> 성능이 만족스럽다면 학습 OK
  성능이 떨어지면 모델의 구조를 수정해 전 단계부터 다시 수행.

※ 교차 검증
- 검증을 약간 변형한 기법, 학습 데이터를 학습과 검증 데이터로 나누는 것은 같지만 고정적이지 않고 계속 바꿔줌
- 즉 학습데이터 검증 데이터를 처음에 정한 대로 계속 사용하지 않고 중간중간 다시 바꿔주는 것.
- why? 데이터를 고정해 놓으면 모데링 검증용 데이터에도 과적합될 여지가 있기 때문이다.
- 데이터를 고정시키지 않음으로 과적합 여부를 차단하기 위함이다.

# 머신러닝의 종류
- 크게 세 종류로 나뉨
1. 지도학습
- 사람이 무엇인가 배우는 과정과 비슷함. 연습 문제를 풀며 새로운 지식을 공부하는 과정
- 훈련 데이터로 부터 예측, 추정, 분류 함수를 만들어 내는 기계학습 방법.
- 독립변수들과 종속변수를 가지고 있고 훈련 데이터를 입력시킴으로 독립변수와 족송변수 간 관계를 일반화하는 학습
- Y값을 가지고 있으니 학습이 끝나면 성과가 나옴. > 예측율
- 모델링이 끝나면 학습 모델에 새로운 데이터를 적용해 예첵, 추정, 분류 등 과업을 수행함.

- 지도학습에서 학습은 입력에 대한 모델의 출력과 정답의 차이가 줄도록 모델을 수정ㅎ나느 과정을 의미함.
- 지도학습으로 완벽하게 학습된 모델은 학습 데이터에서 입력을 받으면 주어진 해당 정답을 출력함 > 당연한 소리

2. 비지도학습
- 학습 데이터는 입력만 있고 정답은 없는 형태로 되어 있음.
- 주로 데이터의 특성을 분석하거나 데이터를 가공하는데에 사용됨. 
- 정답이 없으니 해법은 학습이 불가능, 문제의 구문이나 형태를 가지고 유형을 나누어 봄.
- 관찰한 데이터로 부터 숨겨진 패턴, 규칙을 탐색하고 찾아내는 머신러닝 기법이다.
- 종속변수가 없으며 Input 변수만 입력, 컴퓨터에게 숨어져 있는 패턴을 찾으라고 명령하는 것.
- 차원 축소, 네트워크 분석 등이 비지도학습에 속함.

- 비지도학습은 분석 초기 탐색적분석(EDA, Exploratory Data Analysis) 단계에 많이 사용됨.
- 비즈니스 과업의 많은 경우 비지도학습과 지도학습을 서로 연계해 사용하는 경우가 많음.

3. 강화학습
- 입력과 출력, 출력에 대한 평가의 쌍을 학습 데이터로 사용함.
- 주로 제어나 게임 플레이 등 상호작용을 통해 최적의 동작을 학습해야 될 때 사용함.
- 강화학습은 명시적인 학습이 없이도 동적으로 변화하는 환경과 상호작용하며 특정 목적을 숳애할 수 있는 컴퓨터 프로그램
  을 말한다. (예 - 무인 자동차 등)
- 다른 예로 알파고와 같이 대전 게임하는 방법을 배우는 것.
- 강화학습은 장기관점의 보상을 최대화하기 위해 agent가 변화하는 환경에서 무슨 행동을 취해야 하는지 대해 주목한다.
- 강화학습 알고리즘은 환경의 변화에 따라 취해야 할 행동을 매핑(선택)하는 정책을 찾는 시도랄한다.
  강화학습은 지도학습과 달리 정확한 input/output 데이터나 최적의 행동 집합을 필요로 하지 않는다.
- 우리가 보통 인공지능 이라고 말할 때 생각하는 머신러닝은 강화학습과 관련이 많이 있어보인다.
- 딥러닝 + 강화학습은 사람이 개입하지 않아도 행동을 알아서 취하기 때문에 인공지능의 핵심으로 부상한 것.
- 제약조건을 만족하는 하에서 최적화가 역동적으로 변화하는 환경에 대응해 실시간으로 계산해 적용하고 실시간으로
  피드백 받는 동적인 시스템을 생각하면 된다.


# 지도학습의 특징
- 모델의 쓰임새에 따라 크게 분류(classifier)와 회귀(regression)으로 나눌 수 있다.
- 분류는 머신러닝 분야에서 가장 많이 다루는 문제이며 말 그대로 입력 데이터가 어느 범주에 속하는지 알아내는 것.
- ex) 스팸 메일 분류, 숫자 인식, 얼굴 인식 등
- 분류 문제에서 학습 데이터는 입력 데이터와 결과에 해당하는 범주로 이루어져있다.
- 해당 관측치의 독립 변수들과 종속 변수가 주어지는 것.

- 회귀 문제는 범주를 추정하는 것이 아닌 어떤 값을 예측한다. 이 점이 분류와 다름.
- 예를 들어 나이별 소득 데이터를 통해 나이에 따른 소득을 예측하는 모델을 구하는 것과 같은 예측 모델.
- 학습 데이터는 입력값과 예측값 두 가지로 나온ㄷ.
- 지도학습인 분류와 회귀 모두 학습 데이터가 입력,정답을 가지고 있고 두 가지는 정답의 형태가 다를 뿐이다.



# 인공지능 (Artificial Inteligence)
- 보통 규칙을 수식 안에 잘 입력한 방정식을 Weal AI라고 부름.
- 이미지로 검색, 스마트폰 AI시스템, 챗봇 등이 그 예이다. 미리 정의된 규칙을 통해 단순 반복독작이 아닌
  지능적 행동을 할 수 있도록 구현한 알고리즘을 말함.
- 진짜 정의 : 컴퓨터가 지능있는 인간처럼 해동하도록 만든 알고리즘이라고 볼 수 있다.



  



