# kNN(k-Nearest Neighbor) 지도학습 - 분류(Classifier)
- 분류를 위한 대표적인 알고리즘
- 가장 단순한 머신러닝 알고리즘 중 하나지만 광범위하게 사용된다.

※ kNN 장점
1. 단순하고 효율적이다.
2. 기저 데이터 분포에 대한 가정을 하지 않는다.
3. 훈련 단계가 빠르다.

※ kNN 단점
1. 모델을 생성하지 않아 특징과 클래스 간 관계를 이해하는 능력이 제한됨.
2. 적절한 k의 선택이 필요함.
3. 분류 단계가 느리다.
4. 명목 특징 및 누락 데이터를 위한 추가 처리가 필요함.
- 글자 k는 사용자가 정의하는 최근접 이웃의 개수를 의미함.

※ kNN 알고리즘 데이터 분석 순서
1. k를 지정한다.
2. 훈련 데이터를 기반으로 학습 후 데이터를 분류한다.
3. 새로운 테스트 인스턴스가 들어왔을 때 학습 결과를 기반으로 분류한다.

- kNN알고리즘에서 가장 중요한 것은 k값 설정이다.
- kNN 분류 모형은 새로운 데이터에 대해 이와 가장 유사한 k 개의 학습 데이터(과거 자료)의 결과를 이용해
  다수결로 분류하기 때문이다.
- 과거 자료를 이용하여 미리 분류모형을 수립하는 것이 아니라 저장만 해두고 필요시 비교를 수행하는 방식임.
- k값의 선택에 따라 새로운 데이터에 대한 분류결과가 달라짐에 유의하여야 함.
- 또한 kNN은 반응변수가 범주형인 경우 분류(classification)의 목적으로, 반응변수가 연속형인 경우 회귀
  (regression)으로 사용될 수 있다.
- kNN은 머신러닝 분야에서 가장 단순한 알고리즘이다. 이는 지역 정보만으로 근사되고 모든 계산이 이루어진 후
  분류가 이루어지는 특징으로 인해 사례-기반 학습 또는 lazy learning의 한 유형으로 볼 수 있음.
- 사례-기반 학습은 메모리에 저장되어 있는 과거 학습 데이터로부터 직접 결과가 도출(분류가 수행) 메모리 기반 학습
  이라고도 한다.
  



